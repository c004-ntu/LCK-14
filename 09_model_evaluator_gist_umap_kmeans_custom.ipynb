{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class  for evaluating BERTopic models using OCTIS framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\anaconda3\\envs\\bertopic_39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Chris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# %% [code]\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Tuple\n",
    "from collections import Counter\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "import networkx as nx\n",
    "from bertopic import BERTopic\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import warnings\n",
    "import traceback\n",
    "\n",
    "# Define the LemmaTokenizer so that it is available during unpickling.\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        # Tokenize and lemmatize the document.\n",
    "        return [self.wnl.lemmatize(token) for token in word_tokenize(doc)]\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    nltk.download('punkt')\n",
    "    NLTK_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f\"Warning: NLTK data download failed: {e}\")\n",
    "    NLTK_AVAILABLE = False\n",
    "\n",
    "class OCTISEvaluator:\n",
    "    \"\"\"\n",
    "    OCTIS-based evaluator for comprehensive topic model assessment.\n",
    "    \n",
    "    This class implements evaluation metrics from the OCTIS framework, combined with\n",
    "    recommendations from the BERTopic authors. It calculates coherence, diversity,\n",
    "    quality, clustering, and significance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str):\n",
    "        self.model_path = model_path\n",
    "        self.model = None\n",
    "        self.topics = {}\n",
    "        self.topic_words = []\n",
    "        self.documents = []\n",
    "        self.tokenized_docs = []\n",
    "        self.metrics = {}\n",
    "        \n",
    "    def load_model(self) -> bool:\n",
    "        \"\"\"Load the BERTopic model.\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading model from {self.model_path}...\")\n",
    "            self.model = BERTopic.load(self.model_path)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            return False\n",
    "            \n",
    "    def extract_topics(self) -> bool:\n",
    "        \"\"\"Extract topics from the model.\"\"\"\n",
    "        try:\n",
    "            if not self.model:\n",
    "                print(\"Model not loaded. Call load_model() first.\")\n",
    "                return False\n",
    "            self.topics = self.model.get_topics()\n",
    "            # Convert topics for coherence calculation\n",
    "            self.topic_words = []\n",
    "            for topic_id, words in self.topics.items():\n",
    "                if topic_id != -1:  # Skip outlier topic\n",
    "                    top_words = [word for word, _ in words[:10]]\n",
    "                    self.topic_words.append(top_words)\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting topics: {e}\")\n",
    "            return False\n",
    "            \n",
    "    def load_documents(self, docs_path: str) -> bool:\n",
    "        \"\"\"Load and preprocess documents.\"\"\"\n",
    "        try:\n",
    "            if docs_path.endswith('.xlsx'):\n",
    "                df = pd.read_excel(docs_path)\n",
    "                display(df.head(2))\n",
    "                display(df.dtypes)\n",
    "                self.documents = df[\"abstract_content_clean_en\"].fillna(\"\").tolist()\n",
    "            else:\n",
    "                with open(docs_path, 'r', encoding='utf-8') as f:\n",
    "                    self.documents = f.readlines()\n",
    "            self._tokenize_documents()\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading documents: {e}\")\n",
    "            return False\n",
    "            \n",
    "    def _tokenize_documents(self):\n",
    "        \"\"\"Tokenize documents for coherence calculation.\"\"\"\n",
    "        if not NLTK_AVAILABLE:\n",
    "            print(\"NLTK not available. Install nltk for tokenization.\")\n",
    "            return\n",
    "        try:\n",
    "            tokenizer = WordNetLemmatizer()\n",
    "            self.tokenized_docs = []\n",
    "            for doc in self.documents:\n",
    "                if not isinstance(doc, str):\n",
    "                    doc = str(doc)\n",
    "                tokens = word_tokenize(doc.lower())\n",
    "                tokens = [tokenizer.lemmatize(token) for token in tokens]\n",
    "                tokens = [token for token in tokens if len(token) > 2 and any(c.isalpha() for c in token)]\n",
    "                if tokens:\n",
    "                    self.tokenized_docs.append(tokens)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in tokenization: {e}\")\n",
    "            traceback.print_exc()\n",
    "            \n",
    "    def calculate_coherence(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate coherence metrics: c_v, u_mass, and c_npmi.\n",
    "        \"\"\"\n",
    "        if not self.tokenized_docs or not self.topic_words:\n",
    "            print(\"Documents or topics not available.\")\n",
    "            return {}\n",
    "        try:\n",
    "            dictionary = Dictionary(self.tokenized_docs)\n",
    "            coherence_scores = {}\n",
    "            for measure in ['c_v', 'u_mass', 'c_npmi']:\n",
    "                try:\n",
    "                    coherence_model = CoherenceModel(\n",
    "                        topics=self.topic_words,\n",
    "                        texts=self.tokenized_docs,\n",
    "                        dictionary=dictionary,\n",
    "                        coherence=measure\n",
    "                    )\n",
    "                    score = coherence_model.get_coherence()\n",
    "                    coherence_scores[f\"coherence_{measure}\"] = score\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating {measure} coherence: {e}\")\n",
    "            return coherence_scores\n",
    "        except Exception as e:\n",
    "            print(f\"Error in coherence calculation: {e}\")\n",
    "            return {}\n",
    "            \n",
    "    def calculate_diversity(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate diversity metrics including topic diversity and word overlap.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            all_words = [word for topic in self.topic_words for word in topic]\n",
    "            unique_words = set(all_words)\n",
    "            diversity = len(unique_words) / len(all_words) if all_words else 0\n",
    "            total_overlap = 0\n",
    "            max_overlap = 0\n",
    "            min_overlap = float('inf')\n",
    "            overlaps = []\n",
    "            for i in range(len(self.topic_words)):\n",
    "                for j in range(i+1, len(self.topic_words)):\n",
    "                    set_i = set(self.topic_words[i])\n",
    "                    set_j = set(self.topic_words[j])\n",
    "                    overlap = len(set_i.intersection(set_j))\n",
    "                    total_overlap += overlap\n",
    "                    max_overlap = max(max_overlap, overlap)\n",
    "                    min_overlap = min(min_overlap, overlap)\n",
    "                    overlaps.append(overlap)\n",
    "            avg_overlap = total_overlap / len(overlaps) if overlaps else 0\n",
    "            overlap_std = np.std(overlaps) if overlaps else 0\n",
    "            return {\n",
    "                \"topic_diversity\": diversity,\n",
    "                \"avg_word_overlap\": avg_overlap,\n",
    "                \"max_word_overlap\": max_overlap,\n",
    "                \"min_word_overlap\": min_overlap,\n",
    "                \"overlap_std\": overlap_std,\n",
    "                \"unique_words_ratio\": len(unique_words) / len(self.topic_words) if self.topic_words else 0\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating diversity: {e}\")\n",
    "            return {}\n",
    "            \n",
    "    def calculate_topic_quality(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate topic quality metrics including average words per topic and word score statistics.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            words_per_topic = [len(topic) for topic in self.topic_words]\n",
    "            avg_words = np.mean(words_per_topic)\n",
    "            std_words = np.std(words_per_topic)\n",
    "            all_scores = []\n",
    "            for topic_id, words in self.topics.items():\n",
    "                if topic_id != -1:\n",
    "                    scores = [score for _, score in words]\n",
    "                    all_scores.extend(scores)\n",
    "            return {\n",
    "                \"avg_words_per_topic\": avg_words,\n",
    "                \"std_words_per_topic\": std_words,\n",
    "                \"avg_word_score\": np.mean(all_scores) if all_scores else 0,\n",
    "                \"min_word_score\": min(all_scores) if all_scores else 0,\n",
    "                \"max_word_score\": max(all_scores) if all_scores else 0,\n",
    "                \"word_score_std\": np.std(all_scores) if all_scores else 0\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating topic quality: {e}\")\n",
    "            return {}\n",
    "            \n",
    "    def calculate_clustering_metrics(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate clustering metrics: silhouette score and Calinski-Harabasz score.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not hasattr(self.model, 'embedding_model') or not self.documents:\n",
    "                return {}\n",
    "            embeddings = self.model.embedding_model.encode(self.documents)\n",
    "            doc_topics = self.model.transform(self.documents)[0]\n",
    "            try:\n",
    "                silhouette = silhouette_score(embeddings, doc_topics)\n",
    "            except:\n",
    "                silhouette = 0\n",
    "            try:\n",
    "                calinski = calinski_harabasz_score(embeddings, doc_topics)\n",
    "            except:\n",
    "                calinski = 0\n",
    "            return {\n",
    "                \"silhouette_score\": silhouette,\n",
    "                \"calinski_harabasz_score\": calinski\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating clustering metrics: {e}\")\n",
    "            return {}\n",
    "            \n",
    "    def calculate_topic_significance(self) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate topic significance metrics: entropy and topic size statistics.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.model or not hasattr(self.model, 'topic_sizes_'):\n",
    "                return {}\n",
    "            topic_sizes = self.model.topic_sizes_\n",
    "            total_docs = sum(topic_sizes.values())\n",
    "            probs = np.array(list(topic_sizes.values())) / total_docs\n",
    "            entropy = -np.sum(probs * np.log2(probs + 1e-10))\n",
    "            sizes = np.array(list(topic_sizes.values()))\n",
    "            return {\n",
    "                \"topic_entropy\": entropy,\n",
    "                \"avg_topic_size\": np.mean(sizes),\n",
    "                \"std_topic_size\": np.std(sizes),\n",
    "                \"min_topic_size\": np.min(sizes),\n",
    "                \"max_topic_size\": np.max(sizes)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating topic significance: {e}\")\n",
    "            return {}\n",
    "            \n",
    "    def evaluate(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Run comprehensive evaluation following OCTIS framework and return metrics.\n",
    "        \"\"\"\n",
    "        print(\"\\nStarting OCTIS-based evaluation...\")\n",
    "        if not self.model and not self.load_model():\n",
    "            return {}\n",
    "        if not self.topics and not self.extract_topics():\n",
    "            return {}\n",
    "        metrics = {}\n",
    "        print(\"\\nCalculating coherence metrics...\")\n",
    "        coherence = self.calculate_coherence()\n",
    "        if coherence:\n",
    "            metrics.update(coherence)\n",
    "        print(\"Calculating diversity metrics...\")\n",
    "        diversity = self.calculate_diversity()\n",
    "        if diversity:\n",
    "            metrics.update(diversity)\n",
    "        print(\"Calculating quality metrics...\")\n",
    "        quality = self.calculate_topic_quality()\n",
    "        if quality:\n",
    "            metrics.update(quality)\n",
    "        print(\"Calculating clustering metrics...\")\n",
    "        clustering = self.calculate_clustering_metrics()\n",
    "        if clustering:\n",
    "            metrics.update(clustering)\n",
    "        print(\"Calculating significance metrics...\")\n",
    "        significance = self.calculate_topic_significance()\n",
    "        if significance:\n",
    "            metrics.update(significance)\n",
    "        self.metrics = metrics\n",
    "        return metrics\n",
    "        \n",
    "    def display_results(self):\n",
    "        \"\"\"\n",
    "        Display evaluation results as formatted DataFrames in the notebook.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Build DataFrame for Table 1: Top 15 Topics\n",
    "            topics_data = []\n",
    "            if hasattr(self.model, 'topic_sizes_'):\n",
    "                top_topics = sorted(self.model.topic_sizes_.items(), key=lambda x: x[1], reverse=True)[:15]\n",
    "                total_docs = sum(self.model.topic_sizes_.values())\n",
    "                rep_docs = {}\n",
    "                if hasattr(self.model, 'representative_docs_'):\n",
    "                    rep_docs = self.model.representative_docs_\n",
    "                for topic_id, size in top_topics:\n",
    "                    if topic_id != -1:\n",
    "                        topic_words = [f\"{word} ({score:.3f})\" for word, score in self.topics[topic_id][:10]]\n",
    "                        topic_label = self.model.topic_labels_[topic_id] if hasattr(self.model, 'topic_labels_') else f\"Topic {topic_id}\"\n",
    "                        doc_percent = (size / total_docs) * 100\n",
    "                        rep_doc = rep_docs.get(topic_id, \"-\") if rep_docs else \"-\"\n",
    "                        topics_data.append({\n",
    "                            \"Topic ID\": topic_id,\n",
    "                            \"Topic Label\": topic_label,\n",
    "                            \"Key Terms\": \", \".join(topic_words),\n",
    "                            \"Document %\": f\"{doc_percent:.1f}%\",\n",
    "                            \"Representative Article\": rep_doc\n",
    "                        })\n",
    "            topics_df = pd.DataFrame(topics_data)\n",
    "            \n",
    "            # Build DataFrame for Table 3: Evaluation Metrics\n",
    "            metrics_data = []\n",
    "            metrics_info = {\n",
    "                'topic_diversity': {\n",
    "                    'name': 'Topic Diversity',\n",
    "                    'benchmark': '>0.7 considered good',\n",
    "                    'interpret': lambda x: 'Excellent - minimal vocabulary overlap' if x > 0.9 \n",
    "                            else 'Good - distinct vocabularies' if x > 0.7 \n",
    "                            else 'Fair'\n",
    "                },\n",
    "                'avg_word_overlap': {\n",
    "                    'name': 'Average Word Overlap',\n",
    "                    'benchmark': '<0.05 considered good',\n",
    "                    'interpret': lambda x: 'Very low - semantically distinct' if x < 0.02\n",
    "                            else 'Good - clear separation' if x < 0.05\n",
    "                            else 'Fair'\n",
    "                },\n",
    "                'coherence_c_v': {\n",
    "                    'name': 'C_v Coherence',\n",
    "                    'benchmark': '>0.4 considered good',\n",
    "                    'interpret': lambda x: 'Excellent - highly coherent' if x > 0.5\n",
    "                            else 'Good - semantically related' if x > 0.4\n",
    "                            else 'Fair'\n",
    "                },\n",
    "                'coherence_u_mass': {\n",
    "                    'name': 'U Measure',\n",
    "                    'benchmark': '<-8.0 acceptable',\n",
    "                    'interpret': lambda x: 'Good - strong specificity' if x < -10\n",
    "                            else 'Acceptable' if x < -8\n",
    "                            else 'Fair'\n",
    "                },\n",
    "                'silhouette_score': {\n",
    "                    'name': 'Silhouette Coefficient',\n",
    "                    'benchmark': '>0 considered good',\n",
    "                    'interpret': lambda x: 'Good - clear separation' if x > 0.2\n",
    "                            else 'Fair' if x > 0\n",
    "                            else 'Poor'\n",
    "                }\n",
    "            }\n",
    "            for metric_key, info in metrics_info.items():\n",
    "                if metric_key in self.metrics:\n",
    "                    value = self.metrics[metric_key]\n",
    "                    interpretation = info['interpret'](value)\n",
    "                    metrics_data.append({\n",
    "                        \"Metric\": info['name'],\n",
    "                        \"Value\": value,\n",
    "                        \"Interpretation\": interpretation,\n",
    "                        \"Benchmark\": info['benchmark']\n",
    "                    })\n",
    "            metrics_df = pd.DataFrame(metrics_data)\n",
    "            \n",
    "            # Optional: Display some introductory text with corpus statistics\n",
    "            num_topics = len([t for t in self.topics.keys() if t != -1])\n",
    "            total_docs = sum(self.model.topic_sizes_.values()) if hasattr(self.model, 'topic_sizes_') else 0\n",
    "            vocab_size = len(set([word for topic in self.topics.values() for word, _ in topic]))\n",
    "            avg_words_per_topic = np.mean([len(words) for words in self.topics.values()])\n",
    "            intro_text = (f\"The BERTopic model successfully identified {num_topics} major thematic areas within the corpus.\\n\"\n",
    "                        f\"Corpus Statistics: {total_docs:,} articles processed, with an effective vocabulary of {vocab_size:,} unique terms, \"\n",
    "                        f\"and an average of {avg_words_per_topic:.1f} key terms per topic.\\n\")\n",
    "            print(intro_text)\n",
    "            \n",
    "            # Display the DataFrames in Jupyter Notebook\n",
    "            print(\"Table 1: Top 15 Topics Identified in Corpus\")\n",
    "            display(topics_df)\n",
    "            print(\"\\nTable 3: BERTopic Model Evaluation Metrics\")\n",
    "            display(metrics_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying results: {e}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    # The following helper methods are stubs for additional analysis sections.\n",
    "    def _write_topic_analysis_section(self, output_func):\n",
    "        output_func(\"## 5.1 In-Depth Analysis of Key Topics\\n\")\n",
    "        significant_topics = self._get_significant_topics()\n",
    "        for topic_id in significant_topics:\n",
    "            if topic_id in self.topics:\n",
    "                topic_words = self.topics[topic_id]\n",
    "                topic_label = self.model.topic_labels_[topic_id] if hasattr(self.model, 'topic_labels_') else f\"Topic {topic_id}\"\n",
    "                topic_size = self.model.topic_sizes_[topic_id] if hasattr(self.model, 'topic_sizes_') else 0\n",
    "                total_docs = sum(self.model.topic_sizes_.values()) if hasattr(self.model, 'topic_sizes_') else 1\n",
    "                topic_percentage = (topic_size / total_docs) * 100\n",
    "                output_func(f\"### {topic_label}\\n\")\n",
    "                output_func(f\"This topic covers {topic_percentage:.1f}% of the corpus with key terms:\\n\")\n",
    "                for word, score in topic_words[:10]:\n",
    "                    output_func(f\"- **{word}** ({score:.3f})\\n\")\n",
    "    \n",
    "    def _write_temporal_analysis_section(self, output_func):\n",
    "        output_func(\"## 5.2 Temporal Analysis\\n\")\n",
    "        output_func(\"Temporal analysis not implemented.\\n\")\n",
    "                \n",
    "    def _write_lifecycle_analysis_section(self, output_func):\n",
    "        output_func(\"## 5.3 Topic Lifecycle Analysis\\n\")\n",
    "        output_func(\"Lifecycle analysis not implemented.\\n\")\n",
    "                \n",
    "    def _write_trending_topics_section(self, output_func):\n",
    "        output_func(\"## 5.4 Trending and Declining Topics\\n\")\n",
    "        output_func(\"Trending topics analysis not implemented.\\n\")\n",
    "            \n",
    "    def _write_cooccurrence_section(self, output_func):\n",
    "        output_func(\"## 5.5 Topic Co-occurrence Patterns\\n\")\n",
    "        output_func(\"Co-occurrence analysis not implemented.\\n\")\n",
    "                \n",
    "    def _write_similarity_section(self, output_func):\n",
    "        output_func(\"## 5.6 Topic Similarity Mapping\\n\")\n",
    "        output_func(\"Similarity mapping not implemented.\\n\")\n",
    "                \n",
    "    def _write_hierarchy_section(self, output_func):\n",
    "        output_func(\"## 5.7 Topic Hierarchy\\n\")\n",
    "        output_func(\"Hierarchy analysis not implemented.\\n\")\n",
    "                \n",
    "    def _get_significant_topics(self) -> List[int]:\n",
    "        if not hasattr(self.model, 'topic_sizes_'):\n",
    "            return []\n",
    "        topic_scores = {}\n",
    "        for topic_id, size in self.model.topic_sizes_.items():\n",
    "            if topic_id != -1:\n",
    "                coherence = self.metrics.get(f'topic_coherence_{topic_id}', 0)\n",
    "                topic_scores[topic_id] = (size * coherence) if coherence > 0 else size\n",
    "        return sorted(topic_scores.keys(), key=lambda x: topic_scores[x], reverse=True)[:5]\n",
    "    \n",
    "    def _analyze_temporal_patterns(self, evolution: Dict) -> Dict[str, List[Tuple[int, str]]]:\n",
    "        return {}\n",
    "        \n",
    "    def _analyze_topic_lifecycles(self) -> Dict[str, List[int]]:\n",
    "        return {}\n",
    "        \n",
    "    def _analyze_topic_trends(self) -> Tuple[List[Tuple[int, float]], List[Tuple[int, float]]]:\n",
    "        return [], []\n",
    "        \n",
    "    def _analyze_topic_clusters(self) -> Dict[str, List[int]]:\n",
    "        return {}\n",
    "        \n",
    "    def _analyze_topic_similarities(self) -> Dict[str, List[Tuple[int, int, float]]]:\n",
    "        return {}\n",
    "        \n",
    "    def _analyze_topic_hierarchy(self) -> Dict[str, List[int]]:\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from model/bertopic_model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_url</th>\n",
       "      <th>article_title</th>\n",
       "      <th>article_title_clean</th>\n",
       "      <th>article_publication_date</th>\n",
       "      <th>author</th>\n",
       "      <th>author_clean</th>\n",
       "      <th>keyword</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract_clean</th>\n",
       "      <th>abstract_clean_en</th>\n",
       "      <th>lang</th>\n",
       "      <th>archive_url</th>\n",
       "      <th>archive_title</th>\n",
       "      <th>archive_title_clean</th>\n",
       "      <th>archive_publication_date</th>\n",
       "      <th>content_url</th>\n",
       "      <th>content</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>abstract_content_clean_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://firstmonday.org/ojs/index.php/fm/artic...</td>\n",
       "      <td>The Lives and Death of Moore's Law</td>\n",
       "      <td>the lives and death of moore's law</td>\n",
       "      <td>2002-11-04</td>\n",
       "      <td>Ilkka Tuomi</td>\n",
       "      <td>Ilkka Tuomi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moore's Law has been an important benchmark f...</td>\n",
       "      <td>moore's law has been an important benchmark f...</td>\n",
       "      <td>moore's law has been an important benchmark f...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://firstmonday.org/ojs/index.php/fm/issue...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-11-04</td>\n",
       "      <td>https://firstmonday.org/ojs/index.php/fm/artic...</td>\n",
       "      <td>The lives and death of Moore's Law\\nMoore’s La...</td>\n",
       "      <td>the lives and death of moore's law moore s law...</td>\n",
       "      <td>moore's law has been an important benchmark f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://firstmonday.org/ojs/index.php/fm/artic...</td>\n",
       "      <td>Terms of public service: Framing mobile privac...</td>\n",
       "      <td>terms of public service: framing mobile privac...</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>Pawel Popiel</td>\n",
       "      <td>Pawel Popiel</td>\n",
       "      <td>mobile privacy, framing, privacy coverage, pri...</td>\n",
       "      <td>Engaging normative theories of the press and r...</td>\n",
       "      <td>engaging normative theories of the press and r...</td>\n",
       "      <td>engaging normative theories of the press and r...</td>\n",
       "      <td>en</td>\n",
       "      <td>https://firstmonday.org/ojs/index.php/fm/issue...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>https://firstmonday.org/ojs/index.php/fm/artic...</td>\n",
       "      <td>Terms of public service: Framing mobile privac...</td>\n",
       "      <td>terms of public service: framing mobile privac...</td>\n",
       "      <td>engaging normative theories of the press and r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_url  \\\n",
       "0  https://firstmonday.org/ojs/index.php/fm/artic...   \n",
       "1  https://firstmonday.org/ojs/index.php/fm/artic...   \n",
       "\n",
       "                                       article_title  \\\n",
       "0                 The Lives and Death of Moore's Law   \n",
       "1  Terms of public service: Framing mobile privac...   \n",
       "\n",
       "                                 article_title_clean article_publication_date  \\\n",
       "0                 the lives and death of moore's law               2002-11-04   \n",
       "1  terms of public service: framing mobile privac...               2019-11-01   \n",
       "\n",
       "         author  author_clean  \\\n",
       "0   Ilkka Tuomi   Ilkka Tuomi   \n",
       "1  Pawel Popiel  Pawel Popiel   \n",
       "\n",
       "                                             keyword  \\\n",
       "0                                                NaN   \n",
       "1  mobile privacy, framing, privacy coverage, pri...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0   Moore's Law has been an important benchmark f...   \n",
       "1  Engaging normative theories of the press and r...   \n",
       "\n",
       "                                      abstract_clean  \\\n",
       "0   moore's law has been an important benchmark f...   \n",
       "1  engaging normative theories of the press and r...   \n",
       "\n",
       "                                   abstract_clean_en lang  \\\n",
       "0   moore's law has been an important benchmark f...   en   \n",
       "1  engaging normative theories of the press and r...   en   \n",
       "\n",
       "                                         archive_url archive_title  \\\n",
       "0  https://firstmonday.org/ojs/index.php/fm/issue...           NaN   \n",
       "1  https://firstmonday.org/ojs/index.php/fm/issue...           NaN   \n",
       "\n",
       "   archive_title_clean archive_publication_date  \\\n",
       "0                  NaN               2002-11-04   \n",
       "1                  NaN               2019-11-01   \n",
       "\n",
       "                                         content_url  \\\n",
       "0  https://firstmonday.org/ojs/index.php/fm/artic...   \n",
       "1  https://firstmonday.org/ojs/index.php/fm/artic...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The lives and death of Moore's Law\\nMoore’s La...   \n",
       "1  Terms of public service: Framing mobile privac...   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  the lives and death of moore's law moore s law...   \n",
       "1  terms of public service: framing mobile privac...   \n",
       "\n",
       "                           abstract_content_clean_en  \n",
       "0   moore's law has been an important benchmark f...  \n",
       "1  engaging normative theories of the press and r...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "article_url                          object\n",
       "article_title                        object\n",
       "article_title_clean                  object\n",
       "article_publication_date     datetime64[ns]\n",
       "author                               object\n",
       "author_clean                         object\n",
       "keyword                              object\n",
       "abstract                             object\n",
       "abstract_clean                       object\n",
       "abstract_clean_en                    object\n",
       "lang                                 object\n",
       "archive_url                          object\n",
       "archive_title                        object\n",
       "archive_title_clean                 float64\n",
       "archive_publication_date     datetime64[ns]\n",
       "content_url                          object\n",
       "content                              object\n",
       "content_clean                        object\n",
       "abstract_content_clean_en            object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting OCTIS-based evaluation...\n",
      "\n",
      "Calculating coherence metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chris\\anaconda3\\envs\\bertopic_39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Chris\\anaconda3\\envs\\bertopic_39\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating diversity metrics...\n",
      "Calculating quality metrics...\n",
      "Calculating clustering metrics...\n",
      "Error calculating clustering metrics: 'SentenceTransformerBackend' object has no attribute 'encode'\n",
      "Calculating significance metrics...\n",
      "\n",
      "Evaluation Metrics:\n",
      "coherence_c_v: 0.525482328992997\n",
      "coherence_u_mass: nan\n",
      "coherence_c_npmi: nan\n",
      "topic_diversity: 0.9514285714285714\n",
      "avg_word_overlap: 0.031932773109243695\n",
      "max_word_overlap: 3\n",
      "min_word_overlap: 0\n",
      "overlap_std: 0.22601136771783853\n",
      "unique_words_ratio: 9.514285714285714\n",
      "avg_words_per_topic: 10.0\n",
      "std_words_per_topic: 0.0\n",
      "avg_word_score: 0.218897328192405\n",
      "min_word_score: 0.1477035672955659\n",
      "max_word_score: 0.5187392100088899\n",
      "word_score_std: 0.051049585521936634\n",
      "topic_entropy: 5.010404555984249\n",
      "avg_topic_size: 68.94285714285714\n",
      "std_topic_size: 27.994839174536494\n",
      "min_topic_size: 23\n",
      "max_topic_size: 125\n",
      "The BERTopic model successfully identified 35 major thematic areas within the corpus.\n",
      "Corpus Statistics: 2,413 articles processed, with an effective vocabulary of 333 unique terms, and an average of 10.0 key terms per topic.\n",
      "\n",
      "Table 1: Top 15 Topics Identified in Corpus\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic ID</th>\n",
       "      <th>Topic Label</th>\n",
       "      <th>Key Terms</th>\n",
       "      <th>Document %</th>\n",
       "      <th>Representative Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6_education_learning_distance education_student</td>\n",
       "      <td>education (0.240), learning (0.220), distance ...</td>\n",
       "      <td>5.2%</td>\n",
       "      <td>[ globalization represents a significant threa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>15_twitter_tweet_political_social medium</td>\n",
       "      <td>twitter (0.242), tweet (0.178), political (0.1...</td>\n",
       "      <td>5.1%</td>\n",
       "      <td>[the social live streaming service twitch was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>33_museum_archive_preservation_digital collection</td>\n",
       "      <td>museum (0.297), archive (0.228), preservation ...</td>\n",
       "      <td>5.1%</td>\n",
       "      <td>[ syracuse university library's belfer audio l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>7_queer_shame_hiv_woman</td>\n",
       "      <td>queer (0.256), shame (0.233), hiv (0.233), wom...</td>\n",
       "      <td>4.4%</td>\n",
       "      <td>[the internet and hiv biomedical technologies ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>17_censorship_russia_authoritarian_internet</td>\n",
       "      <td>censorship (0.211), russia (0.200), authoritar...</td>\n",
       "      <td>4.4%</td>\n",
       "      <td>[ in october the bbc aired a short series of r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>16_journal_publishing_open access_scholarly pu...</td>\n",
       "      <td>journal (0.301), publishing (0.295), open acce...</td>\n",
       "      <td>4.4%</td>\n",
       "      <td>[ historically, agricultural research and educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2_bot_qanon_troll_election</td>\n",
       "      <td>bot (0.256), qanon (0.232), troll (0.212), ele...</td>\n",
       "      <td>3.9%</td>\n",
       "      <td>[an internet troll is a person who deliberatel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>32_economy_sharing economy_gift_gift economy</td>\n",
       "      <td>economy (0.225), sharing economy (0.225), gift...</td>\n",
       "      <td>3.8%</td>\n",
       "      <td>[ web . has been a dominant concept in recent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>30</td>\n",
       "      <td>30_political participation_political_civic_par...</td>\n",
       "      <td>political participation (0.215), political (0....</td>\n",
       "      <td>3.8%</td>\n",
       "      <td>[the late case of the facebook content moderat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0_open source_floss_linux_source software</td>\n",
       "      <td>open source (0.355), floss (0.313), linux (0.2...</td>\n",
       "      <td>3.6%</td>\n",
       "      <td>[ starting with eric raymond's groundbreaking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>21_rural_rural development_digital divide_e-media</td>\n",
       "      <td>rural (0.251), rural development (0.232), digi...</td>\n",
       "      <td>3.4%</td>\n",
       "      <td>[ this is a call for a \"grand challenge\" proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>10_music_copyright_napster_music industry</td>\n",
       "      <td>music (0.373), copyright (0.276), napster (0.2...</td>\n",
       "      <td>3.4%</td>\n",
       "      <td>[ this paper is included in the first monday s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>14_search_engine_search engine_web</td>\n",
       "      <td>search (0.306), engine (0.286), search engine ...</td>\n",
       "      <td>3.1%</td>\n",
       "      <td>[ web search engines are beginning to offer pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>12_blog_youtube_fashion_blogging</td>\n",
       "      <td>blog (0.232), youtube (0.198), fashion (0.194)...</td>\n",
       "      <td>3.1%</td>\n",
       "      <td>[in an increasingly overloaded information env...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>22</td>\n",
       "      <td>22_privacy_online privacy_video evidence_priva...</td>\n",
       "      <td>privacy (0.320), online privacy (0.190), video...</td>\n",
       "      <td>2.9%</td>\n",
       "      <td>[in may , the united states office of the dire...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic ID                                        Topic Label  \\\n",
       "0          6    6_education_learning_distance education_student   \n",
       "1         15           15_twitter_tweet_political_social medium   \n",
       "2         33  33_museum_archive_preservation_digital collection   \n",
       "3          7                            7_queer_shame_hiv_woman   \n",
       "4         17        17_censorship_russia_authoritarian_internet   \n",
       "5         16  16_journal_publishing_open access_scholarly pu...   \n",
       "6          2                         2_bot_qanon_troll_election   \n",
       "7         32       32_economy_sharing economy_gift_gift economy   \n",
       "8         30  30_political participation_political_civic_par...   \n",
       "9          0          0_open source_floss_linux_source software   \n",
       "10        21  21_rural_rural development_digital divide_e-media   \n",
       "11        10          10_music_copyright_napster_music industry   \n",
       "12        14                 14_search_engine_search engine_web   \n",
       "13        12                   12_blog_youtube_fashion_blogging   \n",
       "14        22  22_privacy_online privacy_video evidence_priva...   \n",
       "\n",
       "                                            Key Terms Document %  \\\n",
       "0   education (0.240), learning (0.220), distance ...       5.2%   \n",
       "1   twitter (0.242), tweet (0.178), political (0.1...       5.1%   \n",
       "2   museum (0.297), archive (0.228), preservation ...       5.1%   \n",
       "3   queer (0.256), shame (0.233), hiv (0.233), wom...       4.4%   \n",
       "4   censorship (0.211), russia (0.200), authoritar...       4.4%   \n",
       "5   journal (0.301), publishing (0.295), open acce...       4.4%   \n",
       "6   bot (0.256), qanon (0.232), troll (0.212), ele...       3.9%   \n",
       "7   economy (0.225), sharing economy (0.225), gift...       3.8%   \n",
       "8   political participation (0.215), political (0....       3.8%   \n",
       "9   open source (0.355), floss (0.313), linux (0.2...       3.6%   \n",
       "10  rural (0.251), rural development (0.232), digi...       3.4%   \n",
       "11  music (0.373), copyright (0.276), napster (0.2...       3.4%   \n",
       "12  search (0.306), engine (0.286), search engine ...       3.1%   \n",
       "13  blog (0.232), youtube (0.198), fashion (0.194)...       3.1%   \n",
       "14  privacy (0.320), online privacy (0.190), video...       2.9%   \n",
       "\n",
       "                               Representative Article  \n",
       "0   [ globalization represents a significant threa...  \n",
       "1   [the social live streaming service twitch was ...  \n",
       "2   [ syracuse university library's belfer audio l...  \n",
       "3   [the internet and hiv biomedical technologies ...  \n",
       "4   [ in october the bbc aired a short series of r...  \n",
       "5   [ historically, agricultural research and educ...  \n",
       "6   [an internet troll is a person who deliberatel...  \n",
       "7   [ web . has been a dominant concept in recent ...  \n",
       "8   [the late case of the facebook content moderat...  \n",
       "9   [ starting with eric raymond's groundbreaking ...  \n",
       "10  [ this is a call for a \"grand challenge\" proje...  \n",
       "11  [ this paper is included in the first monday s...  \n",
       "12  [ web search engines are beginning to offer pe...  \n",
       "13  [in an increasingly overloaded information env...  \n",
       "14  [in may , the united states office of the dire...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table 3: BERTopic Model Evaluation Metrics\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "      <th>Interpretation</th>\n",
       "      <th>Benchmark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Topic Diversity</td>\n",
       "      <td>0.951429</td>\n",
       "      <td>Excellent - minimal vocabulary overlap</td>\n",
       "      <td>&gt;0.7 considered good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Average Word Overlap</td>\n",
       "      <td>0.031933</td>\n",
       "      <td>Good - clear separation</td>\n",
       "      <td>&lt;0.05 considered good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_v Coherence</td>\n",
       "      <td>0.525482</td>\n",
       "      <td>Excellent - highly coherent</td>\n",
       "      <td>&gt;0.4 considered good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U Measure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fair</td>\n",
       "      <td>&lt;-8.0 acceptable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Metric     Value                          Interpretation  \\\n",
       "0       Topic Diversity  0.951429  Excellent - minimal vocabulary overlap   \n",
       "1  Average Word Overlap  0.031933                 Good - clear separation   \n",
       "2         C_v Coherence  0.525482             Excellent - highly coherent   \n",
       "3             U Measure       NaN                                    Fair   \n",
       "\n",
       "               Benchmark  \n",
       "0   >0.7 considered good  \n",
       "1  <0.05 considered good  \n",
       "2   >0.4 considered good  \n",
       "3       <-8.0 acceptable  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [code]\n",
    "# Update these paths with the correct locations for your BERTopic model and document file.\n",
    "model_path = \"model/bertopic_model\"      # e.g., \"./model/bertopic_model\"\n",
    "docs_path = \"data/archives_articles_contents.xlsx\"   # or \"your_documents.xlsx\" if using an Excel file\n",
    "\n",
    "# Create an evaluator instance.\n",
    "evaluator = OCTISEvaluator(model_path=model_path)\n",
    "\n",
    "# Load the model.\n",
    "if evaluator.load_model():\n",
    "    # Extract topics from the model.\n",
    "    evaluator.extract_topics()\n",
    "    \n",
    "    # Load documents (ensure the document file exists and the column name is correct for Excel files).\n",
    "    if evaluator.load_documents(docs_path):\n",
    "        # Run the evaluation and print the evaluation metrics.\n",
    "        metrics = evaluator.evaluate()\n",
    "        print(\"\\nEvaluation Metrics:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "        \n",
    "        # Display the full evaluation report directly in the notebook.\n",
    "        evaluator.display_results()\n",
    "    else:\n",
    "        print(\"Failed to load documents.\")\n",
    "else:\n",
    "    print(\"Failed to load model.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
